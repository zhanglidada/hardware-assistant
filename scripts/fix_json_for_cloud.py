#!/usr/bin/env python3
"""
ä¿®å¤JSONæ•°æ®æ ¼å¼ä»¥æ»¡è¶³å¾®ä¿¡äº‘æ•°æ®åº“å¯¼å…¥è¦æ±‚

è¦æ±‚ï¼š
1. JSON Linesæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
2. é”®åä¸èƒ½ä»¥`.`å¼€å¤´æˆ–ç»“å°¾ï¼Œä¸èƒ½æœ‰è¿ç»­çš„`.`
3. é”®åä¸èƒ½é‡å¤
4. æ—¶é—´æ ¼å¼å¿…é¡»ä¸ºISODateæ ¼å¼ï¼š{"$date": "ISOå­—ç¬¦ä¸²"}
5. _idå­—æ®µå¿…é¡»å”¯ä¸€
6. å¤„ç†CSVæ ¼å¼ï¼ˆæœ¬è„šæœ¬ä¸»è¦å¤„ç†JSONï¼‰

è¾“å‡ºï¼šç¬¦åˆè¦æ±‚çš„JSONLæ–‡ä»¶
"""

import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Set
import hashlib


class JSONFixer:
    """JSONæ•°æ®ä¿®å¤å™¨"""
    
    def __init__(self):
        self.duplicate_keys_warning = False
        self.invalid_keys_warning = False
        
    def is_valid_key(self, key: str) -> bool:
        """
        æ£€æŸ¥é”®åæ˜¯å¦æœ‰æ•ˆ
        è¦æ±‚ï¼šä¸èƒ½ä»¥`.`å¼€å¤´æˆ–ç»“å°¾ï¼Œä¸èƒ½æœ‰è¿ç»­çš„`.`
        """
        if key.startswith('.') or key.endswith('.'):
            return False
        if '..' in key:
            return False
        return True
    
    def fix_key_name(self, key: str) -> str:
        """
        ä¿®å¤æ— æ•ˆçš„é”®å
        """
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„.
        key = key.strip('.')
        # æ›¿æ¢è¿ç»­çš„.ä¸ºå•ä¸ª_
        key = re.sub(r'\.{2,}', '_', key)
        # å¦‚æœé”®åä»ç„¶ä»¥.å¼€å¤´æˆ–ç»“å°¾ï¼Œæ·»åŠ å‰ç¼€/åç¼€
        if key.startswith('.'):
            key = 'key_' + key
        if key.endswith('.'):
            key = key + '_value'
        return key
    
    def check_duplicate_keys(self, obj: Dict) -> bool:
        """
        æ£€æŸ¥å¯¹è±¡ä¸­æ˜¯å¦æœ‰é‡å¤é”®å
        """
        keys = list(obj.keys())
        unique_keys = set(keys)
        if len(keys) != len(unique_keys):
            print(f"âš ï¸ å‘ç°é‡å¤é”®å: {[k for k in keys if keys.count(k) > 1]}")
            return True
        return False
    
    def check_nested_ambiguity(self, obj: Dict, parent_key: str = "") -> List[str]:
        """
        æ£€æŸ¥åµŒå¥—é”®åçš„æ­§ä¹‰ï¼ˆå¦‚ {"a": {"b": 1}, "a.b": 2}ï¼‰
        """
        issues = []
        flat_keys = set()
        
        def flatten_dict(d: Dict, prefix: str = ""):
            for k, v in d.items():
                full_key = f"{prefix}.{k}" if prefix else k
                if isinstance(v, dict):
                    flatten_dict(v, full_key)
                else:
                    if full_key in flat_keys:
                        issues.append(full_key)
                    flat_keys.add(full_key)
        
        flatten_dict(obj)
        return issues
    
    def convert_to_isodate(self, date_str: str) -> Dict[str, str]:
        """
        å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºISODateæ ¼å¼
        æ ¼å¼: {"$date": "2018-08-31T17:30:00.882Z"}
        """
        try:
            # å°è¯•è§£æå¸¸è§æ—¥æœŸæ ¼å¼
            formats = [
                "%Y-%m-%d",
                "%Y-%m-%dT%H:%M:%S",
                "%Y-%m-%dT%H:%M:%S.%f",
                "%Y/%m/%d",
                "%Yå¹´%mæœˆ%dæ—¥"
            ]
            
            dt = None
            for fmt in formats:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    break
                except ValueError:
                    continue
            
            if dt is None:
                # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
                print(f"âš ï¸ æ— æ³•è§£ææ—¥æœŸ: {date_str}")
                return {"$date": f"{date_str}T00:00:00.000Z"}
            
            # è½¬æ¢ä¸ºISOæ ¼å¼å¹¶æ·»åŠ Zæ—¶åŒº
            iso_str = dt.isoformat()
            if '.' not in iso_str:
                iso_str += '.000'
            iso_str += 'Z'
            
            return {"$date": iso_str}
            
        except Exception as e:
            print(f"âŒ æ—¥æœŸè½¬æ¢é”™è¯¯ {date_str}: {e}")
            return {"$date": f"{date_str}T00:00:00.000Z"}
    
    def generate_unique_id(self, data: Dict, index: int) -> str:
        """
        ç”Ÿæˆå”¯ä¸€çš„_idå­—æ®µ
        ä½¿ç”¨æ•°æ®å“ˆå¸Œ + ç´¢å¼•ç¡®ä¿å”¯ä¸€æ€§
        """
        # åˆ›å»ºæ•°æ®çš„å­—ç¬¦ä¸²è¡¨ç¤º
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        # ç”ŸæˆMD5å“ˆå¸Œ
        hash_obj = hashlib.md5(data_str.encode('utf-8'))
        hash_hex = hash_obj.hexdigest()[:12]  # å–å‰12ä½
        # ç»„åˆç´¢å¼•å’Œå“ˆå¸Œ
        return f"id_{index:04d}_{hash_hex}"
    
    def fix_object(self, obj: Dict, index: int) -> Dict:
        """
        ä¿®å¤å•ä¸ªJSONå¯¹è±¡
        """
        fixed_obj = {}
        seen_keys = set()
        
        # æ£€æŸ¥å¹¶ä¿®å¤é”®å
        for key, value in obj.items():
            original_key = key
            
            # æ£€æŸ¥é”®åæœ‰æ•ˆæ€§
            if not self.is_valid_key(key):
                self.invalid_keys_warning = True
                key = self.fix_key_name(key)
                print(f"âš ï¸ ä¿®å¤æ— æ•ˆé”®å: {original_key} -> {key}")
            
            # æ£€æŸ¥é‡å¤é”®å
            if key in seen_keys:
                self.duplicate_keys_warning = True
                # æ·»åŠ åç¼€é¿å…é‡å¤
                suffix = 1
                new_key = f"{key}_{suffix}"
                while new_key in seen_keys:
                    suffix += 1
                    new_key = f"{key}_{suffix}"
                print(f"âš ï¸ é¿å…é‡å¤é”®å: {key} -> {new_key}")
                key = new_key
            
            seen_keys.add(key)
            
            # é€’å½’å¤„ç†åµŒå¥—å¯¹è±¡
            if isinstance(value, dict):
                value = self.fix_object(value, index)
            elif isinstance(value, list):
                # å¤„ç†åˆ—è¡¨ä¸­çš„å¯¹è±¡
                value = [self.fix_object(item, i) if isinstance(item, dict) else item 
                        for i, item in enumerate(value)]
            
            # æ£€æŸ¥æ—¥æœŸå­—æ®µå¹¶è½¬æ¢
            if key.lower() in ['date', 'releasedate', 'createdate', 'updatedate', 'timestamp']:
                if isinstance(value, str):
                    value = self.convert_to_isodate(value)
            
            fixed_obj[key] = value
        
        # ç¡®ä¿æœ‰_idå­—æ®µä¸”å”¯ä¸€
        if '_id' not in fixed_obj:
            fixed_obj['_id'] = self.generate_unique_id(fixed_obj, index)
        
        return fixed_obj
    
    def fix_json_file(self, input_path: Path, output_path: Path) -> bool:
        """
        ä¿®å¤JSONæ–‡ä»¶
        """
        try:
            print(f"ğŸ“– è¯»å–æ–‡ä»¶: {input_path}")
            
            # è¯»å–JSONæ–‡ä»¶
            with open(input_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            # å°è¯•è§£æä¸ºJSONæ•°ç»„
            try:
                data = json.loads(content)
                if not isinstance(data, list):
                    print(f"âŒ æ–‡ä»¶ä¸æ˜¯JSONæ•°ç»„: {input_path}")
                    return False
            except json.JSONDecodeError:
                # å¯èƒ½æ˜¯JSON Linesæ ¼å¼ï¼Œå°è¯•é€è¡Œè§£æ
                print(f"âš ï¸ å°è¯•ä½œä¸ºJSON Linesè§£æ: {input_path}")
                lines = [line.strip() for line in content.split('\n') if line.strip()]
                data = []
                for line in lines:
                    try:
                        obj = json.loads(line)
                        data.append(obj)
                    except json.JSONDecodeError as e:
                        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
                        return False
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(data)} æ¡è®°å½•")
            
            # ä¿®å¤æ¯æ¡è®°å½•
            fixed_data = []
            seen_ids = set()
            
            for i, obj in enumerate(data):
                print(f"ğŸ”§ ä¿®å¤è®°å½• {i+1}/{len(data)}")
                fixed_obj = self.fix_object(obj, i)
                
                # æ£€æŸ¥_idå”¯ä¸€æ€§
                obj_id = fixed_obj.get('_id')
                if obj_id in seen_ids:
                    print(f"âš ï¸ å‘ç°é‡å¤_id: {obj_id}ï¼Œç”Ÿæˆæ–°çš„_id")
                    fixed_obj['_id'] = self.generate_unique_id(fixed_obj, i + 1000)
                    seen_ids.add(fixed_obj['_id'])
                else:
                    seen_ids.add(obj_id)
                
                fixed_data.append(fixed_obj)
            
            # å†™å…¥JSON Linesæ ¼å¼
            print(f"ğŸ’¾ å†™å…¥æ–‡ä»¶: {output_path}")
            with open(output_path, 'w', encoding='utf-8') as f:
                for i, obj in enumerate(fixed_data):
                    json_line = json.dumps(obj, ensure_ascii=False)
                    f.write(json_line)
                    if i < len(fixed_data) - 1:
                        f.write('\n')
            
            # æ‰“å°ä¿®å¤æ‘˜è¦
            print(f"\nğŸ“‹ ä¿®å¤æ‘˜è¦:")
            print(f"  âœ… æ€»è®°å½•æ•°: {len(fixed_data)}")
            print(f"  âœ… å”¯ä¸€_idæ•°é‡: {len(seen_ids)}")
            if self.duplicate_keys_warning:
                print(f"  âš ï¸ å‘ç°å¹¶ä¿®å¤äº†é‡å¤é”®å")
            if self.invalid_keys_warning:
                print(f"  âš ï¸ å‘ç°å¹¶ä¿®å¤äº†æ— æ•ˆé”®å")
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {input_path}: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ JSONæ•°æ®ä¿®å¤å·¥å…· - å¾®ä¿¡äº‘æ•°æ®åº“å¯¼å…¥ä¼˜åŒ–")
    print("=" * 60)
    
    # è®¾ç½®è·¯å¾„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    mock_dir = project_root / "src" / "mock"
    
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“ Mockæ•°æ®ç›®å½•: {mock_dir}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not mock_dir.exists():
        print(f"âŒ Mockç›®å½•ä¸å­˜åœ¨: {mock_dir}")
        return
    
    # æŸ¥æ‰¾JSONæ–‡ä»¶
    json_files = list(mock_dir.glob("*.json"))
    if not json_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°JSONæ–‡ä»¶: {mock_dir}")
        return
    
    print(f"\nğŸ” æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    # åˆ›å»ºä¿®å¤å™¨å®ä¾‹
    fixer = JSONFixer()
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    results = {}
    for json_file in json_files:
        print(f"\n" + "=" * 60)
        print(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {json_file.name}")
        print("=" * 60)
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶åï¼ˆæ·»åŠ _fixedåç¼€ï¼‰
        output_file = json_file.with_name(f"{json_file.stem}_fixed.jsonl")
        
        # ä¿®å¤æ–‡ä»¶
        success = fixer.fix_json_file(json_file, output_file)
        results[json_file.name] = (success, output_file)
    
    # æ‰“å°ç»“æœæ‘˜è¦
    print(f"\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†ç»“æœæ‘˜è¦")
    print("=" * 60)
    
    successful = 0
    failed = 0
    
    for filename, (success, output_file) in results.items():
        if success:
            print(f"âœ… {filename} -> {output_file.name}")
            successful += 1
        else:
            print(f"âŒ {filename}: å¤„ç†å¤±è´¥")
            failed += 1
    
    print(f"\nğŸ“ˆ æ€»è®¡: {successful} æˆåŠŸ, {failed} å¤±è´¥")
    
    # æä¾›å¯¼å…¥è¯´æ˜
    if successful > 0:
        print(f"\n" + "=" * 60)
        print("ğŸš€ å¾®ä¿¡äº‘æ•°æ®åº“å¯¼å…¥è¯´æ˜")
        print("=" * 60)
        print("""
ä¿®å¤åçš„æ–‡ä»¶å·²ç¬¦åˆå¾®ä¿¡äº‘æ•°æ®åº“å¯¼å…¥è¦æ±‚ï¼š

1. æ ¼å¼è¦æ±‚ï¼š
   - JSON Linesæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªå®Œæ•´JSONå¯¹è±¡ï¼‰
   - é”®åç¬¦åˆè§„èŒƒï¼ˆæ— .å¼€å¤´/ç»“å°¾ï¼Œæ— è¿ç»­.ï¼‰
   - æ—¶é—´å­—æ®µå·²è½¬æ¢ä¸ºISODateæ ¼å¼
   - _idå­—æ®µå”¯ä¸€

2. å¯¼å…¥æ­¥éª¤ï¼š
   a. æ‰“å¼€å¾®ä¿¡å¼€å‘è€…å·¥å…·
   b. è¿›å…¥äº‘å¼€å‘æ§åˆ¶å°
   c. é€‰æ‹©ç›®æ ‡é›†åˆ
   d. ç‚¹å‡»"å¯¼å…¥"æŒ‰é’®
   e. é€‰æ‹©å¯¹åº”çš„_fixed.jsonlæ–‡ä»¶
   f. ç¡®ä¿é€‰æ‹©"JSON Lines"æ ¼å¼
   g. ç‚¹å‡»"å¯¼å…¥"

3. å†²çªå¤„ç†ï¼š
   - ä½¿ç”¨"Insert"æ¨¡å¼æ—¶ï¼Œ_idå­—æ®µä¼šè‡ªåŠ¨å»é‡
   - å»ºè®®å…ˆæ¸…ç©ºé›†åˆå†å¯¼å…¥ï¼Œé¿å…_idå†²çª
        """)
    
    if failed > 0:
        print(f"\nâš ï¸ éƒ¨åˆ†æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1
    else:
        print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†æˆåŠŸï¼")
        return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
