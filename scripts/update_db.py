#!/usr/bin/env python3
"""
ç¡¬ä»¶å‚æ•°å°åŠ©æ‰‹ - ä¸»æ•°æ®æ›´æ–°æ§åˆ¶å™¨
ç”¨äºæ›´æ–°æœ¬åœ°JSONæ•°æ®åº“ï¼ˆcpu_data.json, gpu_data.json, phone_data.jsonï¼‰
"""

import os
import sys
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
MOCK_DIR = PROJECT_ROOT / "src" / "mock"
BACKUP_DIR = PROJECT_ROOT / "scripts" / "backups"
SCRAPERS_DIR = PROJECT_ROOT / "scripts" / "scrapers"

# ç›®æ ‡æ–‡ä»¶é…ç½®
TARGET_FILES = {
    "cpu": MOCK_DIR / "cpu_data.json",
    "gpu": MOCK_DIR / "gpu_data.json", 
    "phone": MOCK_DIR / "phone_data.json"
}

# æ¨¡å—é…ç½®ï¼ˆå‡è®¾çš„scraperæ¨¡å—ï¼‰
SCRAPER_MODULES = {
    "cpu": "scripts.scrapers.cpu",
    "gpu": "scripts.scrapers.gpu",
    "phone": "scripts.scrapers.phone"
}


def ensure_directories() -> None:
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    MOCK_DIR.mkdir(parents=True, exist_ok=True)
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    SCRAPERS_DIR.mkdir(parents=True, exist_ok=True)


def create_backup(file_path: Path) -> Optional[Path]:
    """
    åˆ›å»ºæ–‡ä»¶å¤‡ä»½
    
    Args:
        file_path: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    if not file_path.exists():
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½: {file_path}")
        return None
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•ï¼ˆæŒ‰æ—¥æœŸï¼‰
    today = datetime.now().strftime("%Y%m%d")
    backup_date_dir = BACKUP_DIR / today
    backup_date_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
    backup_name = f"{file_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    backup_path = backup_date_dir / backup_name
    
    try:
        shutil.copy2(file_path, backup_path)
        print(f"âœ…  å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_path}")
        return backup_path
    except Exception as e:
        print(f"âŒ  å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
        return None


def validate_data(data: List[Dict[str, Any]], data_type: str) -> bool:
    """
    éªŒè¯æ•°æ®å®Œæ•´æ€§
    
    Args:
        data: è¦éªŒè¯çš„æ•°æ®åˆ—è¡¨
        data_type: æ•°æ®ç±»å‹æ ‡è¯†
        
    Returns:
        éªŒè¯æ˜¯å¦é€šè¿‡
    """
    if not data:
        print(f"âŒ  {data_type.upper()}æ•°æ®ä¸ºç©º")
        return False
    
    if not isinstance(data, list):
        print(f"âŒ  {data_type.upper()}æ•°æ®ä¸æ˜¯åˆ—è¡¨ç±»å‹")
        return False
    
    # æ£€æŸ¥æ¯ä¸ªé¡¹ç›®çš„åŸºæœ¬å­—æ®µ
    required_fields = ["id", "model", "brand", "price"]
    for i, item in enumerate(data):
        if not isinstance(item, dict):
            print(f"âŒ  ç¬¬{i+1}ä¸ªé¡¹ç›®ä¸æ˜¯å­—å…¸ç±»å‹")
            return False
        
        for field in required_fields:
            if field not in item:
                print(f"âŒ  ç¬¬{i+1}ä¸ªé¡¹ç›®ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # æ£€æŸ¥IDå”¯ä¸€æ€§
        if len([d for d in data if d.get("id") == item["id"]]) > 1:
            print(f"âŒ  å‘ç°é‡å¤ID: {item['id']}")
            return False
    
    print(f"âœ…  {data_type.upper()}æ•°æ®éªŒè¯é€šè¿‡: {len(data)}ä¸ªé¡¹ç›®")
    return True


def save_json(data: List[Dict[str, Any]], file_path: Path) -> bool:
    """
    ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        file_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ…  æ•°æ®ä¿å­˜æˆåŠŸ: {file_path}")
        return True
    except Exception as e:
        print(f"âŒ  æ•°æ®ä¿å­˜å¤±è´¥: {e}")
        return False


def load_existing_data(file_path: Path) -> List[Dict[str, Any]]:
    """
    åŠ è½½ç°æœ‰çš„JSONæ•°æ®
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        åŠ è½½çš„æ•°æ®åˆ—è¡¨ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥åˆ™è¿”å›ç©ºåˆ—è¡¨
    """
    if not file_path.exists():
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            print(f"ğŸ“‚  åŠ è½½ç°æœ‰æ•°æ®: {file_path} ({len(data)}ä¸ªé¡¹ç›®)")
            return data
        else:
            print(f"âŒ  æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›åˆ—è¡¨ç±»å‹: {file_path}")
            return []
    except json.JSONDecodeError as e:
        print(f"âŒ  JSONè§£æå¤±è´¥: {file_path} - {e}")
        return []
    except Exception as e:
        print(f"âŒ  æ–‡ä»¶è¯»å–å¤±è´¥: {file_path} - {e}")
        return []


def compare_data(new_data: List[Dict[str, Any]], old_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    æ¯”è¾ƒæ–°æ—§æ•°æ®
    
    Args:
        new_data: æ–°æ•°æ®
        old_data: æ—§æ•°æ®
        
    Returns:
        æ¯”è¾ƒç»“æœç»Ÿè®¡
    """
    old_ids = {item["id"] for item in old_data}
    new_ids = {item["id"] for item in new_data}
    
    added_ids = new_ids - old_ids
    removed_ids = old_ids - new_ids
    common_ids = old_ids & new_ids
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°çš„é¡¹ç›®
    updated_items = []
    for new_item in new_data:
        if new_item["id"] in common_ids:
            old_item = next(item for item in old_data if item["id"] == new_item["id"])
            if new_item != old_item:
                updated_items.append(new_item["id"])
    
    return {
        "total_new": len(new_data),
        "total_old": len(old_data),
        "added": len(added_ids),
        "removed": len(removed_ids),
        "updated": len(updated_items),
        "unchanged": len(common_ids) - len(updated_items)
    }


def run_scraper(module_name: str) -> Optional[List[Dict[str, Any]]]:
    """
    è¿è¡ŒæŒ‡å®šçš„scraperæ¨¡å—
    
    Args:
        module_name: æ¨¡å—åç§°
        
    Returns:
        scraperè¿”å›çš„æ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
    """
    try:
        # åŠ¨æ€å¯¼å…¥æ¨¡å—
        module_parts = module_name.split(".")
        if len(module_parts) != 3:
            print(f"âŒ  æ¨¡å—åç§°æ ¼å¼é”™è¯¯: {module_name}")
            return None
        
        # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
        if str(PROJECT_ROOT) not in sys.path:
            sys.path.insert(0, str(PROJECT_ROOT))
        
        # å°è¯•å¯¼å…¥æ¨¡å—
        import importlib
        try:
            module = importlib.import_module(module_name)
        except ModuleNotFoundError as e:
            print(f"âš ï¸  æ¨¡å—æœªæ‰¾åˆ°: {module_name}ï¼Œé”™è¯¯: {e}")
            print(f"ğŸ“  å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥...")
            # å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥
            try:
                # æ·»åŠ scriptsç›®å½•åˆ°Pythonè·¯å¾„
                scripts_dir = PROJECT_ROOT / "scripts"
                if str(scripts_dir) not in sys.path:
                    sys.path.insert(0, str(scripts_dir))
                
                # é‡æ–°å°è¯•å¯¼å…¥
                module = importlib.import_module(module_name)
                print(f"âœ…  æ¨¡å—å¯¼å…¥æˆåŠŸï¼ˆä»scriptsç›®å½•ï¼‰")
            except ModuleNotFoundError as e2:
                print(f"âŒ  ä»ç„¶æ— æ³•å¯¼å…¥æ¨¡å—: {e2}")
                print(f"ğŸ“  å½“å‰Pythonè·¯å¾„: {sys.path}")
                print(f"ğŸ“  Scrapersç›®å½•: {SCRAPERS_DIR}")
                return generate_mock_data(module_parts[2])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰runå‡½æ•°
        if not hasattr(module, "run"):
            print(f"âŒ  æ¨¡å—æ²¡æœ‰runå‡½æ•°: {module_name}")
            return generate_mock_data(module_parts[2])
        
        # è¿è¡Œscraper
        print(f"ğŸš€  è¿è¡Œscraper: {module_name}")
        data = module.run()
        
        if not data:
            print(f"âš ï¸  scraperè¿”å›ç©ºæ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return generate_mock_data(module_parts[2])
        
        return data
        
    except Exception as e:
        print(f"âŒ  scraperè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return generate_mock_data(module_parts[2] if len(module_parts) > 2 else "unknown")


def generate_mock_data(data_type: str) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå½“scraperä¸å¯ç”¨æ—¶ï¼‰
    
    Args:
        data_type: æ•°æ®ç±»å‹
        
    Returns:
        æ¨¡æ‹Ÿæ•°æ®
    """
    print(f"ğŸ“  ç”Ÿæˆ{data_type.upper()}æ¨¡æ‹Ÿæ•°æ®")
    
    if data_type == "cpu":
        return [
            {
                "id": "cpu-001",
                "model": "Intel Core i9-14900KS",
                "brand": "Intel",
                "releaseDate": "2024-03-14",
                "price": 5999,
                "description": "Intelç¬¬14ä»£é…·ç¿æ——èˆ°ç‰¹åˆ«ç‰ˆï¼Œ6.2GHzç¿é¢‘",
                "cores": "8P+16E",
                "baseClock": 3.2,
                "boostClock": 6.2,
                "socket": "LGA1700",
                "tdp": 150,
                "integratedGraphics": True,
                "cache": 36
            }
        ]
    elif data_type == "gpu":
        return [
            {
                "id": "gpu-001",
                "model": "NVIDIA GeForce RTX 4090",
                "brand": "NVIDIA",
                "releaseDate": "2024-01-10",
                "price": 12999,
                "description": "NVIDIA Ada Lovelaceæ¶æ„æ——èˆ°æ˜¾å¡",
                "vram": 24,
                "busWidth": 384,
                "cudaCores": 16384,
                "coreClock": 2235,
                "memoryClock": 21000,
                "powerConsumption": 450,
                "rayTracing": True,
                "upscalingTech": "DLSS"
            }
        ]
    elif data_type == "phone":
        return [
            {
                "id": "phone-001",
                "model": "iPhone 15 Pro Max",
                "brand": "Apple",
                "releaseDate": "2024-09-22",
                "price": 9999,
                "description": "è‹¹æœæ——èˆ°æ‰‹æœºï¼ŒA17 ProèŠ¯ç‰‡",
                "processor": "A17 Pro",
                "ram": 8,
                "storage": 256,
                "screenSize": 6.7,
                "resolution": "2796x1290",
                "refreshRate": 120,
                "batteryCapacity": 4422,
                "camera": "48MP+12MP+12MP",
                "os": "iOS",
                "support5G": True
            }
        ]
    else:
        return []


def update_data(data_type: str, target_file: Path) -> bool:
    """
    æ›´æ–°æŒ‡å®šç±»å‹çš„æ•°æ®
    
    Args:
        data_type: æ•°æ®ç±»å‹
        target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ›´æ–°æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{'='*60}")
    print(f"æ›´æ–° {data_type.upper()} æ•°æ®")
    print(f"{'='*60}")
    
    # 1. åˆ›å»ºå¤‡ä»½
    backup_path = create_backup(target_file)
    
    # 2. åŠ è½½ç°æœ‰æ•°æ®
    old_data = load_existing_data(target_file)
    
    # 3. è¿è¡Œscraperè·å–æ–°æ•°æ®
    module_name = SCRAPER_MODULES.get(data_type)
    if not module_name:
        print(f"âŒ  æœªæ‰¾åˆ°{data_type}çš„scraperé…ç½®")
        return False
    
    new_data = run_scraper(module_name)
    if not new_data:
        print(f"âŒ  æ— æ³•è·å–{data_type}æ•°æ®")
        return False
    
    # 4. éªŒè¯æ–°æ•°æ®
    if not validate_data(new_data, data_type):
        print(f"âŒ  {data_type}æ•°æ®éªŒè¯å¤±è´¥")
        return False
    
    # 5. æ¯”è¾ƒæ•°æ®å˜åŒ–
    stats = compare_data(new_data, old_data)
    
    # 6. ä¿å­˜æ–°æ•°æ®
    if not save_json(new_data, target_file):
        # å¦‚æœä¿å­˜å¤±è´¥ï¼Œå°è¯•æ¢å¤å¤‡ä»½
        if backup_path and backup_path.exists():
            print(f"ğŸ”„  å°è¯•æ¢å¤å¤‡ä»½...")
            try:
                shutil.copy2(backup_path, target_file)
                print(f"âœ…  å¤‡ä»½æ¢å¤æˆåŠŸ")
            except Exception as e:
                print(f"âŒ  å¤‡ä»½æ¢å¤å¤±è´¥: {e}")
        return False
    
    # 7. æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š  {data_type.upper()}æ•°æ®æ›´æ–°ç»Ÿè®¡:")
    print(f"   æ€»è®¡é¡¹ç›®: {stats['total_new']} (ä¹‹å‰: {stats['total_old']})")
    print(f"   æ–°å¢é¡¹ç›®: {stats['added']}")
    print(f"   åˆ é™¤é¡¹ç›®: {stats['removed']}")
    print(f"   æ›´æ–°é¡¹ç›®: {stats['updated']}")
    print(f"   æœªå˜é¡¹ç›®: {stats['unchanged']}")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„  ç¡¬ä»¶å‚æ•°å°åŠ©æ‰‹ - æ•°æ®æ›´æ–°æ§åˆ¶å™¨")
    print(f"ğŸ“  é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
    print(f"ğŸ“  Mockæ•°æ®ç›®å½•: {MOCK_DIR}")
    print(f"ğŸ“  å¤‡ä»½ç›®å½•: {BACKUP_DIR}")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_directories()
    
    # æ›´æ–°æ‰€æœ‰ç±»å‹çš„æ•°æ®
    success_count = 0
    total_count = len(TARGET_FILES)
    
    for data_type, target_file in TARGET_FILES.items():
        try:
            if update_data(data_type, target_file):
                success_count += 1
        except Exception as e:
            print(f"âŒ  {data_type.upper()}æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“‹  æ›´æ–°å®Œæˆæ€»ç»“")
    print(f"{'='*60}")
    print(f"âœ…  æˆåŠŸæ›´æ–°: {success_count}/{total_count}")
    print(f"âŒ  å¤±è´¥æ›´æ–°: {total_count - success_count}/{total_count}")
    
    if success_count == total_count:
        print("ğŸ‰  æ‰€æœ‰æ•°æ®æ›´æ–°æˆåŠŸï¼")
        return 0
    elif success_count > 0:
        print("âš ï¸  éƒ¨åˆ†æ•°æ®æ›´æ–°æˆåŠŸ")
        return 1
    else:
        print("âŒ  æ‰€æœ‰æ•°æ®æ›´æ–°å¤±è´¥")
        return 2


if __name__ == "__main__":
    sys.exit(main())
